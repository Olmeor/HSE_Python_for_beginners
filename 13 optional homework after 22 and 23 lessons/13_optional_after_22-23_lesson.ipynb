{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28067cb2",
   "metadata": {},
   "source": [
    "#### Вопрос 1\n",
    "## Проверка работоспособности сайта\n",
    "\n",
    "Вы пишете программу, которая помогает вам определить, работает ли сайт вашей компании или что-то идёт не так. Напишите программу, которая, получив ссылку, выводит строчку “IT WORKS!”, если страницу успешно удалось загрузить и “ERROR” в противном случае \n",
    "\n",
    "#### ФОРМАТ ВВОДА\n",
    "Строка с адресом\n",
    "  \n",
    "#### ФОРМАТ ВЫВОДА\n",
    "\n",
    "Строка \"IT WORKS!\" или \"ERROR\"\n",
    "Страницы, анализируемые в открытом тесте, можно посмотреть [здесь](http://online.hse.ru/python-as-foreign/1/1.html) и [здесь](http://online.hse.ru/python-as-foreign/nonexistent)\n",
    "\n",
    "**Для примера:**\n",
    "\n",
    "| Ввод | Результат |\n",
    "| :- | :-|\n",
    "| http://127.0.0.1/python-as-foreign/1/1.html | IT WORKS! |\n",
    "| http://127.0.0.1/python-as-foreign/nonexistent | ERROR |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366eac49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "response = requests.get(input())\n",
    "try:\n",
    "    response.raise_for_status()\n",
    "    print(\"IT WORKS!\")\n",
    "except:\n",
    "    print(\"ERROR\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49996f31",
   "metadata": {},
   "source": [
    "#### Вопрос 2\n",
    "## Портфолио\n",
    "\n",
    "Веб-разработчица Валя решила собрать свое портфолио — специальную страницу, на которой будут ссылки на все ее работы. Напишите программу, которая поможет ей это сделать.\n",
    "\n",
    "#### ФОРМАТ ВВОДА\n",
    "Строки с адресами сайтов, по одному адресу в строке.\n",
    "В последней строке указано слово \"конец\".\n",
    "\n",
    "ФОРМАТ ВЫВОДА\n",
    "Html-разметка, содержащая перечень введенных ссылок, в следующем формате:\n",
    "На каждой строке должна быть записана строка со ссылкой в формате **\"<.a href=\"ссылка\">Название страницы</a>\"**. Название страницы требуется получить из содержимого тега title со страницы, на которую ведет соответствующая ссылка.\n",
    "Если страницы не существует, ее адрес в портфолио добавлять не нужно.\n",
    "  \n",
    "*Страницы, анализируемые в открытом тесте, можно посмотреть [здесь](http://online.hse.ru/python-as-foreign/1/1.html), [здесь](http://online.hse.ru/python-as-foreign/nonexistent) и [тут](http://online.hse.ru/python-as-foreign/2)\n",
    "Пояснение к примеру: Страница с адресом **http://127.0.0.1/python-as-foreign/nonexistent** не существует.*\n",
    "\n",
    "**Примечание:**\n",
    "\n",
    "При отправке задачи в функцию BeautifulSoup() нужно передать второй аргумент: 'lxml'.\n",
    "Например, вместо кода soup = BeautifulSoup(page.text) нужно написать soup = BeautifulSoup(page.text, 'lxml')\n",
    "  \n",
    "**Для примера:**\n",
    "\n",
    "| Ввод | Результат |\n",
    "| :- | :-|\n",
    "| http://127.0.0.1/python-as-foreign/1/1.html | <a href=\"http://127.0.0.1/python-as-foreign/1/1.html\">Гарри Поттер</a> |\n",
    "| http://127.0.0.1/python-as-foreign/nonexistent | <a href=\"http://127.0.0.1/python-as-foreign/2\">Статистика зарплат по регионам присутствия Вышки</a> |\n",
    "| http://127.0.0.1/python-as-foreign/2 |  |\n",
    "| конец |  |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccb6f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "while True:\n",
    "    url = input()\n",
    "    if url.lower() == 'конец':\n",
    "        break\n",
    "    response = requests.get(url)\n",
    "    try:\n",
    "        response.raise_for_status()\n",
    "        response.encoding = 'utf-8'\n",
    "        soup = BeautifulSoup(response.text, 'lxml')\n",
    "        # print(soup.prettify())\n",
    "        title = soup.find_all('title')[0].text\n",
    "        print(f'<a href=\"{url}\">{title}</a>')\n",
    "    except:\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03764e6",
   "metadata": {},
   "source": [
    "#### Вопрос 3\n",
    "## Сохранённые картинки\n",
    "\n",
    "Вы любите коллекционировать смешные картинки, но вот беда — альбом для сохранённых картинок переполнился. Вы решили написать программу, которая найдёт все адреса картинок (из атрибута src тега img) на странице, чтобы их потом скачать. Если на странице нет ни одной картинки — нужно вывести на экран фразу \"NO PICS FOUND\".\n",
    "\n",
    "#### ФОРМАТ ВВОДА\n",
    "Строка с адресом страницы с картинками\n",
    "  \n",
    "#### ФОРМАТ ВЫВОДА\n",
    "Строки с названиями файлов картинок, по одному названию в строке, в порядке появления адресов в html-коде страницы\n",
    "Если на странице нет ни одной картинки, то выводится строка \"NO PICS FOUND\"\n",
    "\n",
    "*Страницы, анализируемые в открытом тесте, можно посмотреть [здесь](http://online.hse.ru/python-as-foreign/tasks/pics/example.html) и [здесь](http://online.hse.ru/python-as-foreign/tasks/pics/example_nopics.html)*\n",
    "\n",
    "**Примечание:**\n",
    "При отправке задачи в функцию BeautifulSoup() нужно передать второй аргумент: 'lxml'.\n",
    "Например, вместо кода soup = BeautifulSoup(page.text) нужно написать soup = BeautifulSoup(page.text, 'lxml')\n",
    "  \n",
    "**Для примера:**\n",
    "\n",
    "| Ввод | Результат |\n",
    "| :- | :-|\n",
    "| http://127.0.0.1/python-as-foreign/tasks/pics/example.html | 1.png |\n",
    "| | 2.png |\n",
    "| | 3.png |\n",
    "| | 4.jpg |\n",
    "| | 5.png |\n",
    "| http://127.0.0.1/python-as-foreign/tasks/pics/example_nopics.html | NO PICS FOUND |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35370c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = input()\n",
    "response = requests.get(url)\n",
    "response.encoding = 'utf-8'\n",
    "soup = BeautifulSoup(response.text, 'lxml')\n",
    "links = soup.find_all('a')\n",
    "urls = [url + links[i].get('href') for i in range(len(links))]\n",
    "if soup.find_all('img'):\n",
    "    print(*[file.get('src') for file in soup.find_all('img')], sep=\"\\n\")\n",
    "else:\n",
    "    print(\"NO PICS FOUND\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d76bf4",
   "metadata": {},
   "source": [
    "#### Вопрос 4\n",
    "## Максимальная зарплата\n",
    "\n",
    "Вася хочет найти себе работу и просматривает сайт с вакансиями. Помогите ему найти вакансию с самой большой зарплатой на странице.\n",
    "\n",
    "#### ФОРМАТ ВВОДА\n",
    "Строка с адресом страницы с вакансиями. Все названия вакансий и все зарплаты в таблице уникальны, зарплаты могут быть только целыми числами. \n",
    "  \n",
    "#### ФОРМАТ ВЫВОДА\n",
    "Строка вида “<вакансия>: <зарплата> руб.”\n",
    "*Страницу, анализируемую в открытом тесте, можно посмотреть [здесь](http://online.hse.ru/python-as-foreign/tasks/salary/example.html).*\n",
    "\n",
    "При отправке задачи в функцию BeautifulSoup() нужно передать второй аргумент: 'lxml'. Например, вместо кода soup = BeautifulSoup(page.text) нужно написать soup = BeautifulSoup(page.text, 'lxml')\n",
    "  \n",
    "**Для примера:**\n",
    "\n",
    "| Ввод | Результат |\n",
    "| :- | :-|\n",
    "| http://127.0.0.1/python-as-foreign/tasks/salary/example.html | Data Scientist: 200000 руб. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b897b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = input()\n",
    "response = requests.get(url)\n",
    "response.encoding = 'utf-8'\n",
    "soup = BeautifulSoup(response.text, 'lxml')\n",
    "lst = soup.find_all('td')\n",
    "dct = {lst[td].text: int(lst[td + 1].text) for td in range(0, len(lst), 2)}\n",
    "vac = max(dct.items(), key= lambda x: x[1])\n",
    "\n",
    "print(f\"{vac[0]}: {vac[1]} руб.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40cb1376",
   "metadata": {},
   "source": [
    "#### Вопрос 5\n",
    "## Эта музыка будет вечной\n",
    "\n",
    "Полина хочет познакомиться с музыкой новой группы, послушав какие-нибудь три её песни. Помогите Полине выбрать, указав три наиболее прослушиваемые песни группы по данным стриминговых сервисов.\n",
    "\n",
    "#### ФОРМАТ ВВОДА\n",
    "Строка с адресом страницы со статистикой.\n",
    "Гарантируется, что количество воспроизведений каждой песни уникально и все названия песен уникальны, что песен в таблице больше, чем 3.\n",
    "  \n",
    "#### ФОРМАТ ВЫВОДА\n",
    "3 строки с названиями песен, упорядоченными по рейтингу\n",
    "Страницу, анализируемую в открытом тесте, можно посмотреть [здесь](http://online.hse.ru/python-as-foreign/tasks/music/nautilus.html).\n",
    "\n",
    "При отправке задачи в функцию BeautifulSoup() нужно передать второй аргумент: 'lxml'.\n",
    "\n",
    "Например, вместо кода soup = BeautifulSoup(page.text) нужно написать soup = BeautifulSoup(page.text, 'lxml')\n",
    "\n",
    "**Для примера:**\n",
    "\n",
    "| Ввод | Результат |\n",
    "| :- | :-|\n",
    "| http://127.0.0.1/python-as-foreign/tasks/music/nautilus.html | Золотое пятно |\n",
    "| | Матерь Богов |\n",
    "| | Эта Музыка Будет Вечной |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceceacbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = input()\n",
    "response = requests.get(url)\n",
    "response.encoding = 'utf-8'\n",
    "soup = BeautifulSoup(response.text, 'lxml')\n",
    "lst = soup.find_all('td')\n",
    "dct = {lst[td].text: int(lst[td + 1].text) for td in range(0, len(lst), 2)}\n",
    "rating = sorted(dct.items(), key= lambda x: x[1], reverse=True)\n",
    "print(*[rating[i][0] for i in range(3)], sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34014b0a",
   "metadata": {},
   "source": [
    "#### Вопрос 6\n",
    "## Сравнение цен в нескольких магазинах\n",
    "\n",
    "Паша очень хочет купить себе игровую приставку нового поколения, но не хочет переплачивать. Помогите ему найти магазин с самой низкой ценой.\n",
    "\n",
    "#### ФОРМАТ ВВОДА\n",
    "Строка с адресом страницы, где находятся ссылки на страницы магазинов.\n",
    "Гарантируется, что на странице каждого магазина цена только одна и находится внутри тега <i></i>.\n",
    "Гарантируется, что все цены уникальны.\n",
    "  \n",
    "#### ФОРМАТ ВЫВОДА\n",
    "\n",
    "Строка вида “ссылка: цена руб.” для страницы с самой низкой ценой.\n",
    "*Страницу, анализируемую в открытом тесте, можно посмотреть [здесь](http://online.hse.ru/python-as-foreign/tasks/ps5/example/).*\n",
    "\n",
    "При отправке задачи в функцию BeautifulSoup() нужно передать второй аргумент: 'lxml'.\n",
    "\n",
    "Например, вместо кода soup = BeautifulSoup(page.text) нужно написать soup = BeautifulSoup(page.text, 'lxml')\n",
    "\n",
    "**Для примера:**\n",
    "\n",
    "| Ввод | Результат |\n",
    "| :- | :-|\n",
    "| http://127.0.0.1/python-as-foreign/tasks/ps5/example/ | http://127.0.0.1/python-as-foreign/tasks/ps5/example/naudio.html: 42000 руб. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a10bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = input()\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'lxml')\n",
    "links = soup.find_all('a')\n",
    "urls = [url + links[i].get('href') for i in range(len(links))]\n",
    "\n",
    "dct = {}\n",
    "for i, link in enumerate(urls):\n",
    "    new_url = link\n",
    "    new_response = requests.get(new_url)\n",
    "    new_soup = BeautifulSoup(new_response.text, 'lxml')\n",
    "    dct[link] = int(new_soup.find_all('i')[0].text)\n",
    "\n",
    "res = min(dct.items(), key= lambda x: x[1])\n",
    "print(f\"{res[0]}: {res[1]} руб.\")\n",
    "\n",
    "# from bs4 import BeautifulSoup\n",
    "# from selenium import webdriver\n",
    "# import time\n",
    "# \n",
    "# from webdriver_manager.chrome import ChromeDriverManager\n",
    "# from selenium.webdriver.chrome.service import Service\n",
    "# s = Service(ChromeDriverManager().install())\n",
    "# driver = webdriver.Chrome(service=s)\n",
    "# \n",
    "# driver.implicitly_wait(2)\n",
    "# driver.get(input())\n",
    "# soup = BeautifulSoup(driver.page_source)\n",
    "# urls = [url + links[i].get('href') for i in range(len(links))]\n",
    "# \n",
    "# dct = {}\n",
    "# for i, url in enumerate(urls):\n",
    "#     driver.get(url)\n",
    "#     new_soup = BeautifulSoup(driver.page_source)\n",
    "#     dct[link] = int(new_soup.find_all('i')[0].text)\n",
    "#     time.sleep(2)\n",
    "# res = min(dct.items(), key= lambda x: x[1])\n",
    "# print(f\"{res[0]}: {res[1]} руб.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079e0c94",
   "metadata": {},
   "source": [
    "#### Вопрос 7\n",
    "## Переводчик\n",
    "Витя приехал в туристическую поездку без гида. К счастью, у него есть сайт с со словарем, где есть таблица перевода слов для двух языков. Помогите ему понять надписи, которые он видит на улицах.\n",
    "\n",
    "#### ФОРМАТ ВВОДА\n",
    "Строка с текстом, который нужно перевести, без знаков препинания.\n",
    "Строка с названием языка, с которого нужно перевести и, через запятую, названием языка, на который нужно перевести.\n",
    "Ссылка на страницу словаря, где есть колонка слов на языке страны (с которого надо перевести) и родном языке Васи (на который надо перевести).\n",
    "  \n",
    "#### ФОРМАТ ВЫВОДА\n",
    "Строка с переводом.\n",
    "*Страницу, анализируемую в открытом тесте, можно посмотреть [здесь](https://online.hse.ru/python-as-foreign/tasks/dict/example.html).*\n",
    "\n",
    "Пояснение к примеру 1: артикль the не перевёлся, так как в таблице не был указан перевод, и в выводе нет ни перевода этого слова, ни лишнего пробела между “это” и “столица”.\n",
    "\n",
    "Пояснение к примеру 2: одна и та же страница может использоваться для перевода между двумя языками в любую сторону, например, и с английского на русский, и с русского на английский.\n",
    "\n",
    "\n",
    "При отправке задачи в функцию BeautifulSoup() нужно передать второй аргумент: 'lxml'.\n",
    "\n",
    "Например, вместо кода soup = BeautifulSoup(page.text) нужно написать soup = BeautifulSoup(page.text, 'lxml')\n",
    "\n",
    "**Для примера:**\n",
    "\n",
    "| Ввод | Результат |\n",
    "| :- | :-|\n",
    "| London is the capital of Great Britain | Лондон это столица от Великий Британия |\n",
    "| ENG,RUS | |\n",
    "| http://127.0.0.1/python-as-foreign/tasks/dict/example.html | |\n",
    "| пустынная роза | desert rose |\n",
    "| RUS,ENG | |\n",
    "| http://127.0.0.1/python-as-foreign/tasks/dict/example.html | |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3daa82ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "def translate(txt, lang, url):\n",
    "    response = requests.get(url)\n",
    "    response.encoding = 'utf-8'\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "    lst = soup.find_all('td')\n",
    "    dct_1 = {lst[td].text: lst[td + 1].text for td in range(0, len(lst), 2)}\n",
    "    dct_2 = {el[1]: el[0] for el in dct_1.items()}\n",
    "    dct = dct_1 if lang.split(',')[0] == soup.find_all('th')[0].text else dct_2\n",
    "\n",
    "    res = []\n",
    "    for word in text.split():\n",
    "        if word in dct and dct[word] != \"\":\n",
    "            res.append(dct[word])\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "    return \" \".join(res)\n",
    "\n",
    "\n",
    "text, trans, link = [input() for _ in range(3)]\n",
    "print(translate(text, trans, link))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b883982",
   "metadata": {},
   "source": [
    "#### Вопрос 8\n",
    "## Список фильмов\n",
    "\n",
    "Дима хочет ознакомиться с самыми лучшими фильмами в истории и изучает списки с рекомендациями. Напишите программу, которая поможет ему выбрать такие фильмы для просмотра, которые рекомендованы сразу во всех списках. \n",
    "\n",
    "#### ФОРМАТ ВВОДА\n",
    "Строки со ссылками на страницы со списками фильмов, по одной ссылке в строке.\n",
    "После всех ссылок идёт строка со словом “конец”.\n",
    "На каждой странице со списками фильмов указано Название фильма, Режиссёр, Исполнители главных ролей, Рейтинг фильма (целое число от 1 до 5 включительно) и Год выхода на экраны (целое положительное число).\n",
    "  \n",
    "#### ФОРМАТА ВЫВОДА\n",
    "Список фильмов по алфавиту (без учёта регистра), по одному названию в строке.\n",
    "*Cтраницы, анализируемые в открытом тесте, можно посмотреть [здесь](http://online.hse.ru/python-as-foreign/tasks/movies/example.html) и [здесь](http://online.hse.ru/python-as-foreign/tasks/movies/example_second.html).*\n",
    "\n",
    "При отправке задачи в функцию BeautifulSoup() нужно передать второй аргумент: 'lxml'.\n",
    "\n",
    "Например, вместо кода soup = BeautifulSoup(page.text) нужно написать soup = BeautifulSoup(page.text, 'lxml')\n",
    "\n",
    "**Для примера:**\n",
    "\n",
    "| Ввод | Результат |\n",
    "| :- | :-|\n",
    "| http://127.0.0.1/python-as-foreign/tasks/movies/example.html | Земляничная поляна |\n",
    "| http://127.0.0.1/python-as-foreign/tasks/movies/example_second.html | Седьмая печать |\n",
    "| конец |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5b566c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "res = set()\n",
    "while True:\n",
    "    url = input()\n",
    "    if url.lower() == 'конец':\n",
    "        break\n",
    "    response = requests.get(url)\n",
    "    response.encoding = 'utf-8'\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "    \n",
    "    lst = []\n",
    "    for row in soup.find_all('tr')[1:]:\n",
    "        row_data = []\n",
    "        for col in row.find_all('td'):\n",
    "            row_data.append(col.text)\n",
    "        lst.append(tuple([row_data[0], int(row_data[3])]))\n",
    "    if res == set():\n",
    "        res = set(lst)\n",
    "    else:\n",
    "        res &= set(lst)\n",
    "\n",
    "res = sorted(res, key=lambda e: e[0].lower())\n",
    "print(*[film for film, grade in res], sep=\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ed787c",
   "metadata": {},
   "source": [
    "#### Вопрос 9\n",
    "## Фильмография\n",
    "Дима записался в университете на курс по истории кино, где к каждой паре ему задают посмотреть фильмы определенного режиссера. Напишите программу, которая выберет для Димы фильмы нужного режиссёра. Фильмы должны быть отсортированы по рейтингу (сначала фильмы с оценкой 5, потом с оценкой 4, потом 3, 2 и 1), а фильмы с одинаковым рейтингом (например, Седьмая печать и Земляничная поляна имеют одинаковый рейтинг \"5\") — по алфавиту.\n",
    "\n",
    "#### ФОРМАТ ВВОДА\n",
    "Строки со ссылками на страницы со списками фильмов, по одной ссылке в строке.\n",
    "Все строки со ссылками начинаются с http://\n",
    "После всех ссылок идёт строка с именем режиссёра, рейтинг фильмов которого нужно составить, этой строкой ввод заканчивается.\n",
    "На каждой странице со списками фильмов именно в этом порядке указаны: Название фильма, Режиссёр, Исполнители главных ролей, Рейтинг фильма (целое число от 1 до 5 включительно) и Год выхода на экраны (целое положительное число). Гарантируется, что на всех страницах рейтинг каждого фильма один и тот же.\n",
    "  \n",
    "#### ФОРМАТ ВЫВОДА\n",
    "Список фильмов по рейтингу, в случае одинакового рейтинга -- по алфавиту (без учёта регистра), по одному названию в строке и, в скобках, год выхода фильма на экраны.\n",
    "*Страницы, анализируемые в открытом тесте, можно посмотреть [здесь](http://online.hse.ru/python-as-foreign/tasks/movies/example.html) и [здесь](http://online.hse.ru/python-as-foreign/tasks/movies/example_second.html).*\n",
    "\n",
    "\n",
    "При отправке задачи в функцию BeautifulSoup() нужно передать второй аргумент: 'lxml'.\n",
    "\n",
    "Например, вместо кода soup = BeautifulSoup(page.text) нужно написать soup = BeautifulSoup(page.text, 'lxml')\n",
    "\n",
    "**Для примера:**\n",
    "\n",
    "| Ввод | Результат |\n",
    "| :- | :-|\n",
    "| http://127.0.0.1/python-as-foreign/tasks/movies/example.html | Земляничная поляна (1957) |\n",
    "| http://127.0.0.1/python-as-foreign/tasks/movies/example_second.html | Седьмая печать (1957) |\n",
    "| Ингмар Бергман | Фанни и Александр (1982) |\n",
    "| | Час волка (1968) |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd83e8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "res = set()\n",
    "while True:\n",
    "    url = input()\n",
    "    if 'http' not in url:\n",
    "        break\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    response.encoding = 'utf-8'\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "    \n",
    "    lst = []\n",
    "    for row in soup.find_all('tr')[1:]:\n",
    "        row_data = []\n",
    "        for col in row.find_all('td'):\n",
    "            row_data.append(col.text)\n",
    "        lst.append(tuple(row_data))\n",
    "    if res == set():\n",
    "        res = set(lst)\n",
    "    else:\n",
    "        res |= set(lst)\n",
    "\n",
    "res = sorted(res, key=lambda e: (int(row_data[3]), e[0].lower()))\n",
    "print(*[f\"{film[0]} ({film[4]})\" for film in res if film[1] == url], sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e88555d",
   "metadata": {},
   "source": [
    "#### Вопрос 10\n",
    "## Фигурное катание\n",
    "\n",
    "Таня любит фигурное катание и хочет узнать результаты своих любимых фигуристов, но не может, так как на сайте с результатами нет функции поиска, и она страдает от этого. Помогите Тане: найдите среди всех таблиц результатов информацию об интересующих её фигуристах.\n",
    "\n",
    "####ФОРМАТ ВВОДА\n",
    "Строка с первой страницей результатов. На каждой странице результатов есть ровно одна таблица с результатами, состоящая из порядкового номера выступающего, ячейки с именем и ячейками с детализированными результатами. Также на странице находятся ссылка с содержимым \"предыдущая таблица результатов\" (кроме первой страницы) и ссылка с содержимым \"Следующая таблица результатов\" (кроме последней страницы).\n",
    "Строка с фамилией интересующего фигуриста\n",
    "Строка с перечнем столбцов результатов, информация из которых интересует Таню. Названия столбцов указаны через запятую.\n",
    "  \n",
    "#### ФОРМАТ ВЫВОДА\n",
    "\n",
    "Перечень результатов в указанном Таней порядке, результаты из одной таблицы указаны в одной строке через пробел, строки с результатами идут в хронологическом порядке.\n",
    "Пояснение к примеру 1: результаты фигуриста Плисецкого есть только в двух таблицах, так что выведено две строки в хронологическом порядке (сначала из первой таблицы, потом — из третьей).\n",
    "\n",
    "Пояснение к примеру 2: результаты фигуриста Кацуки есть только в двух таблицах, так что выведено две строки в хронологическом порядке (сначала из второй таблицы, потом — из третьей).\n",
    "Пояснение к примеру 3: результаты фигуриста Пролджэ есть только в одной таблице.\n",
    "\n",
    "*Сайт, анализируемый в открытом тесте, можно посмотреть [здесь](http://online.hse.ru/python-as-foreign/tasks/fs/example/).*\n",
    "\n",
    "При отправке задачи в функцию BeautifulSoup() нужно передать второй аргумент: 'lxml'.\n",
    "\n",
    "Например, вместо кода soup = BeautifulSoup(page.text) нужно написать soup = BeautifulSoup(page.text, 'lxml')\n",
    "\n",
    "**Для примера:**\n",
    "\n",
    "| Ввод | Результат |\n",
    "| :- | :-|\n",
    "| http://127.0.0.1/python-as-foreign/tasks/fs/example/ | 82.27 8.40 41.02 |\n",
    "| Плисецкий | 59.29 5.75 30.69 |\n",
    "| TSS,IN,TES |  |\n",
    "| http://127.0.0.1/python-as-foreign/tasks/fs/example/ | 96.00 52.65 8.70 |\n",
    "| Кацуки | 84.87 46.67 7.75 |\n",
    "| TSS,TES,CO |  |\n",
    "| http://127.0.0.1/python-as-foreign/tasks/fs/example/ | 9.45 9.30 |\n",
    "| Пролджэ | |\n",
    "| CO,PE | |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de216501",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "def get_index(url, cols):\n",
    "    response = requests.get(url)\n",
    "    response.encoding = 'utf-8'\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "\n",
    "    id = []\n",
    "    id_list = [soup.find_all('th')[i].text for i in range(len(soup.find_all('th')))]\n",
    "    for col in cols:\n",
    "        if col in id_list:\n",
    "            id.append(id_list.index(col))\n",
    "    \n",
    "    return id\n",
    "\n",
    "\n",
    "def get_result(url, name, cols, next=\"\"):\n",
    "    response = requests.get(url + next)\n",
    "    response.encoding = 'utf-8'\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "\n",
    "    global idx\n",
    "\n",
    "    for row in soup.find_all('tr')[1:]:\n",
    "        row_data = []\n",
    "        for col in row.find_all('td'):\n",
    "            row_data.append(col.text)\n",
    "        if name.lower() in row_data[1].lower():\n",
    "            print(*[row_data [i] for i in idx])\n",
    "\n",
    "    links = soup.find_all('a')\n",
    "    for i, u in enumerate(links):\n",
    "        if \"След\".lower() in u.text.lower():\n",
    "            # print(links[i].get('href'), name, cols)\n",
    "            get_result(url, name, cols, links[i].get('href'))\n",
    "\n",
    "link, surname, columns = [input() for _ in range(3)]\n",
    "idx = get_index(link, columns.split(','))\n",
    "get_result(link, surname, columns.split(','))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bae527",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
